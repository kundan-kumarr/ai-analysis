{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize Your Workspace Space\n",
    "\n",
    "Before we get started on our course, let's take some time to set up and tidy our workspace. As an agentic twist on the matter, we will guide a Large Language Model (LLM) through a series of prompt refinements to create a practical plan to organize your personal work area.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Start with a generic prompt\n",
    "2. Add a professional role\n",
    "3. Introduce concrete constraints\n",
    "4. Bonus: Apply what you've learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# No changes needed in this cell\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "# No changes needed in this cell\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If using the Vocareum API endpoint\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TODO: Fill in the missing parts marked with **********\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m      5\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://openai.vocareum.com/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Uncomment one of the following\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# api_key=\"**********\",  # <--- TODO: Fill in your Vocareum API key here\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# api_key=os.getenv(\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#     \"OPENAI_API_KEY\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# ),  # <-- Alternately, set as an environment variable\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "# If using the Vocareum API endpoint\n",
    "# TODO: Fill in the missing parts marked with **********\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openai.vocareum.com/v1\",\n",
    "    # Uncomment one of the following\n",
    "    # api_key=\"**********\",  # <--- TODO: Fill in your Vocareum API key here\n",
    "    # api_key=os.getenv(\n",
    "    #     \"OPENAI_API_KEY\"\n",
    "    # ),  # <-- Alternately, set as an environment variable\n",
    ")\n",
    "\n",
    "# If using OpenAI's API endpoint\n",
    "# client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class OpenAIModels(str, Enum):\n",
    "    GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "    GPT_41_MINI = \"gpt-4.1-mini\"\n",
    "    GPT_41_NANO = \"gpt-4.1-nano\"\n",
    "\n",
    "# Choose a different model to see different results\n",
    "MODEL = OpenAIModels.GPT_41_NANO\n",
    "\n",
    "def get_completion(system_prompt, user_prompt, model=MODEL):\n",
    "    \"\"\"\n",
    "    Function to get a completion from the OpenAI API.\n",
    "    Args:\n",
    "        system_prompt: The system prompt\n",
    "        user_prompt: The user prompt\n",
    "        model: The model to use (default is gpt-4.1-mini. change to gpt-4o-mini or gpt-4.1-nano for different results)\n",
    "    Returns:\n",
    "        The completion text\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    if system_prompt is not None:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            *messages,\n",
    "        ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "\n",
    "def display_responses(*args):\n",
    "    \"\"\"Helper function to display responses as Markdown, horizontally.\"\"\"\n",
    "    markdown_string = \"<table><tr>\"\n",
    "    # Headers\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<th>System Prompt:<br />{arg['system_prompt']}<br /><br />\"\n",
    "        markdown_string += f\"User Prompt:<br />{arg['user_prompt']}</th>\"\n",
    "    markdown_string += \"</tr>\"\n",
    "    # Rows\n",
    "    markdown_string += \"<tr>\"\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<td>Response:<br />{arg['response']}</td>\"\n",
    "    markdown_string += \"</tr></table>\"\n",
    "    display(Markdown(markdown_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generic Prompt\n",
    "\n",
    "First, let's see what the model produces with a basic prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending prompt to OpenAIModels.GPT_41_NANO model...\n",
      "Response received!\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m baseline_response \u001b[38;5;241m=\u001b[39m get_completion(plain_system_prompt, user_prompt)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse received!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m display_responses(\n\u001b[1;32m     10\u001b[0m     {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: plain_system_prompt,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: baseline_response,\n\u001b[1;32m     14\u001b[0m     }\n\u001b[1;32m     15\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 54\u001b[0m, in \u001b[0;36mdisplay_responses\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     52\u001b[0m     markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<td>Response:<br />\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</td>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</tr></table>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m display(Markdown(markdown_string))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Markdown' is not defined"
     ]
    }
   ],
   "source": [
    "# No changes needed in this cell\n",
    "plain_system_prompt = \"You are a helpful assistant.\"  # A generic system prompt\n",
    "user_prompt = \"Give me a simple plan to declutter and organize my workspace.\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "baseline_response = get_completion(plain_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": plain_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": baseline_response,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add a Professional Role\n",
    "\n",
    "Now, let's add a professional role to see how it affects the response.\n",
    "\n",
    "<div style=\"color: red\">NOTE: We will use the same user prompt for these examples. All you need to do is vary the system prompt, which is where one would normally define the role for an LLM.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending prompt with professional role...\n",
      "Response received!\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse received!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Show last two prompts and responses\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m display_responses(\n\u001b[1;32m     10\u001b[0m     {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: plain_system_prompt,\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: baseline_response,\n\u001b[1;32m     14\u001b[0m     },\n\u001b[1;32m     15\u001b[0m     {\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: role_system_prompt,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: role_response,\n\u001b[1;32m     19\u001b[0m     },\n\u001b[1;32m     20\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 54\u001b[0m, in \u001b[0;36mdisplay_responses\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     52\u001b[0m     markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<td>Response:<br />\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</td>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</tr></table>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m display(Markdown(markdown_string))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Markdown' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Write a system prompt starting with \"You are...\" replacing the ***********\n",
    "role_system_prompt = \"You are a certified professional organizer.\"\n",
    "\n",
    "print(\"Sending prompt with professional role...\")\n",
    "role_response = get_completion(role_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "# Show last two prompts and responses\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": plain_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": baseline_response,\n",
    "    },\n",
    "    {\n",
    "        \"system_prompt\": role_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": role_response,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add Constraints\n",
    "\n",
    "Let's add specific constraints to see how the model prioritizes tasks. Let's add a time constraint, a budget constraint, and other constraints that are important for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending prompt with constraints...\n",
      "Response received!\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse received!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Show last two prompts and responses\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m display_responses(\n\u001b[1;32m     11\u001b[0m     {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: role_system_prompt,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: role_response,\n\u001b[1;32m     15\u001b[0m     },\n\u001b[1;32m     16\u001b[0m     {\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: constraints_system_prompt,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt,\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: constraints_response,\n\u001b[1;32m     20\u001b[0m     },\n\u001b[1;32m     21\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 54\u001b[0m, in \u001b[0;36mdisplay_responses\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     52\u001b[0m     markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<td>Response:<br />\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</td>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</tr></table>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m display(Markdown(markdown_string))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Markdown' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Write a constraints system prompt replacing the ***********\n",
    "constraints_system_prompt = f\"\"\" {role_system_prompt}. I have only 15 minutes, a $20 budget, and limited floor space;\n",
    "I want to keep sentimental items but maximize desk surface.\"\"\"\n",
    "\n",
    "print(\"Sending prompt with constraints...\")\n",
    "constraints_response = get_completion(constraints_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "# Show last two prompts and responses\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": role_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": role_response,\n",
    "    },\n",
    "    {\n",
    "        \"system_prompt\": constraints_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": constraints_response,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Apply what you've learned\n",
    "\n",
    "Try crafting a prompt for one of your own ideas or even a different organization task (e.g., digital file cleanup, closet overhaul)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending custom prompt...\n",
      "Response received!\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m custom_response \u001b[38;5;241m=\u001b[39m get_completion(custom_system_prompt, user_prompt)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse received!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m display_responses(\n\u001b[1;32m     25\u001b[0m     {\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: custom_system_prompt,\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt,\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: custom_response,\n\u001b[1;32m     29\u001b[0m     }\n\u001b[1;32m     30\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 54\u001b[0m, in \u001b[0;36mdisplay_responses\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     52\u001b[0m     markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<td>Response:<br />\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</td>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m markdown_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</tr></table>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m display(Markdown(markdown_string))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Markdown' is not defined"
     ]
    }
   ],
   "source": [
    "# Create your own prompts here!\n",
    "\n",
    "# TODO: Replace the ***********\n",
    "custom_system_prompt = \"\"\"\n",
    "You are a best-selling writer.\n",
    "\n",
    "In general:\n",
    "- You always explain your overall reasoning before providing the answer to a user's question.\n",
    "- Always conclude with a list of action items when asked for advice.\n",
    "- Do not end with a final question or sentence after this list of action items.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "Please generate a list of 10 ideas for an article about the benefits of meditation\n",
    "that millions of people will read and benefit from. The article is for a technical audience. \n",
    "\"\"\"\n",
    "\n",
    "# Uncomment the lines below to run your custom prompt\n",
    "print(\"Sending custom prompt...\")\n",
    "custom_response = get_completion(custom_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": custom_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": custom_response,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this exercise, we explored how different prompt refinements affect the output of an LLM:\n",
    "\n",
    "1. **Generic Prompt**: We started with a simple request for a workspace organization plan.\n",
    "2. **Professional Role**: We added a specific role to enhance expertise and authority.\n",
    "3. **Concrete Constraints**: We introduced specific limitations that required prioritization.\n",
    "4. **Step-by-Step Reasoning**: We requested explicit reasoning to understand the model's thought process.\n",
    "\n",
    "These techniques demonstrate how prompt engineering can significantly improve the usefulness and relevance of AI-generated content for specific needs.\n",
    "\n",
    "Excellent Work! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}